{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Titanic Survival Analysis\n",
    "\n",
    "This notebook demonstrates advanced data analysis and machine learning techniques using the Titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "from src.data_processing import DataProcessor\n",
    "from src.features import FeatureEngineering\n",
    "from src.models import ModelTrainer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix, roc_curve, auc\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Enhanced Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Load and prepare data\n",
    "processor = DataProcessor()\n",
    "df = processor.load_data('../data/raw/titanic.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Info:\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\nMissing Values:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nBasic Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Advanced Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set up the plotting style\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "# Create a figure with multiple subplots\n",
    "fig = plt.figure(figsize=(15, 10))\n",
    "\n",
    "# 1. Age distribution by survival\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.kdeplot(data=df, x='Age', hue='Survived', common_norm=False)\n",
    "plt.title('Age Distribution by Survival')\n",
    "\n",
    "# 2. Fare distribution by class\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(data=df, x='Pclass', y='Fare')\n",
    "plt.title('Fare Distribution by Class')\n",
    "\n",
    "# 3. Survival rate by class and gender\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.barplot(data=df, x='Pclass', y='Survived', hue='Sex')\n",
    "plt.title('Survival Rate by Class and Gender')\n",
    "\n",
    "# 4. Family size analysis\n",
    "df['FamilySize'] = df['SibSp'] + df['Parch'] + 1\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.barplot(data=df, x='FamilySize', y='Survived')\n",
    "plt.title('Survival Rate by Family Size')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Advanced Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Clean data with advanced features\n",
    "df_cleaned = processor.clean_data(\n",
    "    columns=['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked'],\n",
    "    drop_duplicates=True,\n",
    "    fill_na={'Age': df['Age'].median(), 'Embarked': 'S'}\n",
    ")\n",
    "\n",
    "# Create advanced features\n",
    "df_cleaned['FamilySize'] = df_cleaned['SibSp'] + df_cleaned['Parch'] + 1\n",
    "df_cleaned['IsAlone'] = (df_cleaned['FamilySize'] == 1).astype(int)\n",
    "df_cleaned['AgeBin'] = pd.qcut(df_cleaned['Age'], 5)\n",
    "df_cleaned['FareBin'] = pd.qcut(df_cleaned['Fare'], 5)\n",
    "\n",
    "# Feature engineering\n",
    "fe = FeatureEngineering()\n",
    "numeric_cols = ['Age', 'Fare', 'FamilySize']\n",
    "categorical_cols = ['Pclass', 'Sex', 'Embarked', 'IsAlone']\n",
    "\n",
    "df_features = fe.create_features(\n",
    "    df_cleaned,\n",
    "    numeric_columns=numeric_cols,\n",
    "    categorical_columns=categorical_cols\n",
    ")\n",
    "\n",
    "print(\"Final features shape:\", df_features.shape)\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "X = df_features.drop('Survived', axis=1)\n",
    "y = df_features['Survived']\n",
    "\n",
    "# Compare different models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate models\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    trainer = ModelTrainer(model)\n",
    "    X_train, X_test, y_train, y_test = trainer.split_data(X, y)\n",
    "    trainer.train_model(X_train, y_train)\n",
    "    metrics = trainer.evaluate_model(X_test, y_test)\n",
    "    \n",
    "    # Perform cross-validation\n",
    "    cv_scores = cross_val_score(model, X, y, cv=5)\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Test Accuracy': metrics['accuracy'],\n",
    "        'CV Mean': cv_scores.mean(),\n",
    "        'CV Std': cv_scores.std()\n",
    "    })\n",
    "\n",
    "# Display results\n",
    "results_df = pd.DataFrame(results)\n",
    "print(\"Model Comparison:\")\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Best Model Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get the best model (Gradient Boosting)\n",
    "best_model = models['Gradient Boosting']\n",
    "trainer = ModelTrainer(best_model)\n",
    "X_train, X_test, y_train, y_test = trainer.split_data(X, y)\n",
    "trainer.train_model(X_train, y_train)\n",
    "\n",
    "# Plot confusion matrix\n",
    "y_pred = trainer.model.predict(X_test)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "y_pred_proba = trainer.model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Feature Importance and Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': trainer.model.feature_importances_\n",
    "})\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance)\n",
    "plt.title('Feature Importance (Gradient Boosting)')\n",
    "plt.show()\n",
    "\n",
    "# Print key insights\n",
    "print(\"\\nKey Insights:\")\n",
    "print(\"1. Top 3 most important features:\")\n",
    "print(feature_importance.head(3))\n",
    "\n",
    "print(\"\\n2. Model Performance:\")\n",
    "print(f\"Accuracy: {metrics['accuracy']:.2f}\")\n",
    "print(\"\\n3. Classification Report:\")\n",
    "print(metrics['classification_report'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
